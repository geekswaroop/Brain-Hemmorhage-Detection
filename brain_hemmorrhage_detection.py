# -*- coding: utf-8 -*-
"""Brain-Hemmorrhage-Detection.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1nb2xX4ukjkI9wVkVyVqckMi_srxnt6v9
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import cv2
import glob

# %matplotlib inline

from google.colab import drive
drive.mount('/content/drive')

!unzip -uq "/content/drive/My Drive/Data_files.zip" -d "/content/drive/My Drive/"

labels_df = pd.read_csv('/content/drive/My Drive/Data_files/train_labels.csv')



labels_df.shape

labels = np.array(labels_df.iloc[:,0].tolist())

labels

files = sorted(glob.glob('/content/drive/My Drive/Data_files/train_data/*.png'))

train_images = []

train_images = np.array([cv2.imread(path) for path in files])

#images

#images

train_images.shape

labels_df.iloc[:, 0].hist(bins=2)

train_images_df = pd.DataFrame(train_images, columns=['images'])

print(train_images_df.head())
print(train_images_df.shape)

train_images_df.describe()

train_images_df['width'] = train_images_df['images'].apply(lambda x: x.shape[0])
train_images_df['height'] = train_images_df['images'].apply(lambda x: x.shape[1])

train_images_df.head()

train_images_df[['height', 'width']].hist(bins=20)

train_images_df[['height', 'width']].describe()

train_images = np.array([cv2.resize(image, (128, 128)) for image in train_images])

train_images.shape

plt.imshow(train_images[0])

plt.imshow(train_images[149])

plt.figure(figsize=(12, 12))
for i, flip in enumerate([None, -1, 0, 1]):
    plt.subplot(221 + i)
    if flip is None:
        plt.imshow(train_images[10])
    else:
        plt.imshow(cv2.flip(train_images[10], flip))

print(labels)
print(train_images.shape)
print(labels.shape)

labels = np.insert(labels, 0, 0.0, axis=0)

indicies = np.random.permutation(75)
train_true_idx, test_true_idx = indicies[:65], indicies[65:]
train_false_idx, test_false_idx = indicies[:65] + 75, indicies[65:] + 75
train_idx, test_idx = np.append(train_true_idx, train_false_idx), np.append(test_true_idx, test_false_idx)

train_validationX, train_validationY = train_images[train_idx], labels[train_idx]
testX, testY = train_images[test_idx], labels[test_idx]

print(train_validationX.shape, testX.shape)
print(train_validationY.shape, testY.shape)

#from sklearn.model_selection import train_test_split

#train_validationX

import keras
from keras.models import Sequential
from keras.layers import Dense, Input, Flatten, Dropout, Conv2D, MaxPooling2D, GlobalAveragePooling2D, GlobalMaxPooling2D
from keras.callbacks import ModelCheckpoint
from keras.preprocessing.image import ImageDataGenerator
from sklearn.metrics import confusion_matrix

import math

train_image_data = ImageDataGenerator(
    rescale=1./255,
    shear_range=0.,
    zoom_range=0.05,
    rotation_range=180,
    width_shift_range=0.05,
    height_shift_range=0.05,
    horizontal_flip=True,
    vertical_flip=True,
    fill_mode='constant',
    cval=0
)
validation_image_data = ImageDataGenerator(
    rescale=1./255,
    shear_range=0.,
    zoom_range=0.05,
    rotation_range=90,
    width_shift_range=0.05,
    height_shift_range=0.05,
    horizontal_flip=True,
    vertical_flip=True,
    fill_mode='constant',
    cval=0)

plt.figure(figsize=(12, 12))
for X_batch, y_batch in train_image_data.flow(train_validationX, train_validationY, batch_size=9):
    for i in range(0, 9):
        plt.subplot(330 + 1 + i)
        plt.imshow(X_batch[i])
    plt.show()
    break

def check_accuracy(model, setX, actual, print_images=True):
    predicted = np.array([int(x[0] > 0.5) for x in model.predict(setX)])
    if print_images:
        rows = math.ceil(len(predicted)/10.)
        plt.figure(figsize=(20, 3 * rows))
        for i in range(len(predicted)):
            plt.subplot(rows, 10, i+1)
            plt.imshow(setX[i])
            plt.title("pred "+str(predicted[i])+" actual "+str(actual[i]))
        
    confusion = confusion_matrix(actual, predicted)
    tn, fp, fn, tp = confusion.ravel()
    print("True positive:", tp, ", True negative:", tn,
          ", False positive:", fp, ", False negative:", fn)

    print("Total accuracy:", np.sum(predicted==actual) / len(predicted) * 100., "%")
    return (tn, fp, fn, tp)

def simple_conv_model(input_shape):
    model = Sequential()
    
    model.add(Conv2D(32, kernel_size=3, strides=2, padding='same', activation='relu', input_shape=input_shape))
    model.add(MaxPooling2D(pool_size=2))
    model.add(Conv2D(32, kernel_size=3, strides=2, padding='same', activation='relu'))
    model.add(MaxPooling2D(pool_size=2))
    model.add(Conv2D(64, kernel_size=3, strides=2, padding='same', activation='relu'))
    
    model.add(GlobalAveragePooling2D())
    model.add(Dropout(0.4))
    
    model.add(Dense(32, activation='relu'))
    model.add(Dropout(0.4))
    
    model.add(Dense(1, activation='sigmoid'))
    return model

model = simple_conv_model((128, 128, 3))
model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])

model.summary()

model.fit_generator(train_image_data.flow(train_validationX, train_validationY, batch_size=128),
    steps_per_epoch=128,
    validation_data=validation_image_data.flow(testX, testY, batch_size=16),
    validation_steps=100,
    callbacks=[ModelCheckpoint("weights.h5", monitor='val_acc', save_best_only=True, mode='max')],
    epochs=16)

check_accuracy(model, testX/255., testY)

def imbalance_set(coeff=2):
    imbalanced_trainX = []
    imbalanced_trainY = []
    for i, train_x in enumerate(train_validationX):
        def add_entry(x, y):
            imbalanced_trainX.append(x)
            imbalanced_trainY.append(y)

        add_entry(train_x, train_validationY[i])

        if(train_validationY[i] == 1):
            for j in range(coeff-1):
                add_entry(train_x, train_validationY[i])
    return (np.array(imbalanced_trainX), np.array(imbalanced_trainY))

imbalanced_trainX, imbalanced_trainY = imbalance_set(2)
print(imbalanced_trainX.shape, imbalanced_trainY.shape)

def bigger_conv_model(input_shape):
    model = Sequential()
    
    model.add(Conv2D(32, kernel_size=3, strides=2, padding='same', activation='relu', input_shape=input_shape))
    model.add(MaxPooling2D(pool_size=2))
    model.add(Conv2D(32, kernel_size=3, strides=2, padding='same', activation='relu'))
    model.add(MaxPooling2D(pool_size=2))
    model.add(Conv2D(64, kernel_size=3, strides=2, padding='same', activation='relu'))
    
    model.add(GlobalAveragePooling2D())
    model.add(Dropout(0.4))
    
    model.add(Dense(64, activation='relu'))
    model.add(Dropout(0.4))
    
    model.add(Dense(1, activation='sigmoid'))
    return model

model = bigger_conv_model((128, 128, 3))
model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])
model.summary()

model.fit_generator(train_image_data.flow(imbalanced_trainX, imbalanced_trainY, batch_size=128),
    steps_per_epoch=128,
    validation_data=validation_image_data.flow(testX, testY, batch_size=16),
    validation_steps=100,
    callbacks=[ModelCheckpoint("bigger_model_checkpoint_weights.h5", monitor='val_acc', save_best_only=True, mode='max')],
    epochs=24)

check_accuracy(model, train_validationX/255., train_validationY, False)

check_accuracy(model, testX/255., testY, False)

model.load_weights('model_submission.h5')

check_accuracy(model, train_validationX/255., train_validationY, False)

check_accuracy(model, testX/255., testY, False)

